{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97d2a027",
   "metadata": {},
   "source": [
    "# Mediapipe processing\n",
    "This notebook shows how the Corpus NGT videos can be processed using Mediapipe. Currently, a **break** has been added to the for-loop because it is only intended to show an example of the Mediapipe processing. \n",
    "\n",
    "To use the existing code, the break should be removed. We warn that this sequential processing is very slow - each video takes several minutes to process, with about 855 videos total it is expected that several days are needed to process all videos.\n",
    "\n",
    "Because the sequential processing is so slow, it is recommended to implement the video processing in a parallel manner if possible, to allow multiple videos to be processed at a time. We do not demonstrate parallel processing in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d3d464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "# Keep python tools up to date\n",
    "from tools import tools, constants, mediapipe_tools\n",
    "importlib.reload(tools)\n",
    "importlib.reload(mediapipe_tools)\n",
    "importlib.reload(constants)\n",
    "\n",
    "# Import all functions from the tools\n",
    "from tools.tools import*\n",
    "from tools.mediapipe_tools import*\n",
    "from tools.constants import PATHS # Path constants\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba091466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S001_CNGT0090.mpg\n",
      "./CNGT_isolated_signers/S001_CNGT0090.mpg\n",
      "Getting landmarks...\n",
      "Storing new files at: ./CNGT_np_landmarks_test/\n",
      "Done.\n",
      "CPU times: total: 7min 47s\n",
      "Wall time: 7min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Root where all the annotated .eaf sign files are present\n",
    "dataset_root = PATHS['cngt_vids_and_eaf']\n",
    "# remove '/test' here if you process all videos (this suffix is added because this is an example)\n",
    "destination_root = PATHS['root'] + 'CNGT_np_landmarks_test/'\n",
    "\n",
    "# List the .mpg files in the root directory to investigate\n",
    "video_titles = [file for file in os.listdir(dataset_root) if file.endswith('.mpg')]\n",
    "\n",
    "# Get MediaPipe landmarks for each CNGT video, store the results in a .pkl file\n",
    "for video_title in video_titles:\n",
    "    print(video_title)\n",
    "    print(dataset_root + video_title)\n",
    "    save_landmarks_for_video_path(dataset_root, video_title, destination_root, draw = False, log = True)\n",
    "    # Added break because this takes too long on typical hardware, so we just give a test example\n",
    "    # If you want to process all videos the break should naturally be removed\n",
    "    # But be warned: processing all videos can take DAYS (one video takes several minutes and there are hundreds)\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d8dfa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
